# Deep Learning Enabled Single-View Markerless Motion Capture
 
In the video games and film industries, the standard approach to animation is often costly, inconvenient and requires a lot of space. While this is not a pressing issue, solving it could improve the workflow of larger studios and more importantly empower indie developers and hobbyists to easier and quicker realise their vision. Through the use of deep learning and single-camera footage, motion capture could be made more accessible and convenient to work with and if done well could providing immense improvements to motion capture and animation, potentially replace established industry technologies such as optical motion.


## Project Timeline

***18th May - 14th June:*** Research, Project Specification, Literature Review Draft.


***15th June - 29th June:*** Backlog, Sprint 1 (Install Tools, Create UML Class Diagrams, Build Basic CNN with TensorFlow, Load a Video and Extract its Frames)


***30th June - 14th July:*** Sprint 2 (Further Research on Deep Learning for Computer Vision and CNN Configurations, Implement Key Point Detection, Update the Neural Network Configuration Based on Research to Improve Results)


***15th July - 29th July:*** Sprint 3 (Update Literature Review, Depth map Generation from a Single Video, Using the Generated Depth Maps to Rise the Dimension from 2D to 3D)


***30th July - 13th August:*** Sprint 4 (Implement Pre-Convolutional Video Processing to Take Load of the CNN)


***14th August - 28th August:*** Sprint 5 (3rd Party Evaluation, Complete Report and Prototype)


***Future Work:*** Revising Implementation Based on Feedback, Performance Improvements, Integrating the Software with Unreal Engine, Blender, Unity Engine as Well as Allowing a Standalone Use, Refining User Interface, Multi-Person Motion Capture.
